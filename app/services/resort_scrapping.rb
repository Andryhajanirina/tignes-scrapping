class ResortScrapping

  attr_accessor :url, :url_fix_first, :url_fix_second, :url_dates, :url_region, :url_pages, :start_date, :double

  def initialize
    p "Let's scrap the classifieds!"
    # bob = Classified.new
    # bob.save
    @start_date = Date.new

    @url_fix_first = "https://www.abritel.fr/ajax/map/results/refined"
    @url_region = "/region:66612960"
    @url_dates = "/arrival:2017-12-16/departure:2017-12-23"
    @url_fix_second = "/@,,,,z"
    @url_pages = "/page:1"

    @double = 0

    build_url
     
    changeResort
    # getDataFromPage
    puts "number of duplicates avoided: #{@double}"
    
  end

  def build_url
    @url = @url_fix_first + @url_region + @url_dates + @url_fix_second + @url_pages
  end

  def changeResort

    # region_id_list = Resort.pluck(:region_number)
#     region_id_list = [
#       "66613081",
#       "66613021
#       "66613165
#       "66613017
# 66613128
# 66612899
# 66612786
# 66612963
# 66612964
# 66612827
# 66612992
# 66612972
# 66612991
# 66612967
# 66612967
# 66612921
# 66612922
# 6668622
# 6668738
# 6668750
# 6668612
    
    region_id_list.each do |region_id| #Adding the [0..3] to limit the number of tests
     @url_region = "/region:#{region_id}"
     build_url
     puts "*Scrapping for region #{region_id}*"
     changeDate
   end
  
  # Test sur une rÃ©gion
    @url_region = "/region:66612957"
    changeDate

  end
 
  def changeDate
    season_start = Date.new(2017,12,23)
    season_end = Date.new(2018,5,5) #Here change the season end to increase tests
    number_of_weeks = (season_end-season_start)/7
    number_of_weeks = number_of_weeks.to_i

    number_of_weeks.times do |i|
      #change url
      @start_date = season_start + (i-1)*7
      @url_dates = "/arrival:" + start_date.strftime + "/departure:" + (start_date+7).strftime + "/"
      build_url
      puts "***Scrapping for starting date #{@start_date}***"
      changePage
    end

  end
  
  def changePage

    #Getting the total number of pages to scrap
    @url_pages = "/page:1"
    build_url
    page = HTTParty.get(@url)
    current_number_of_pages = JSON.parse(page.body)["results"]["pageCount"]

    # current_number_of_pages = 1 #just to test with fewer pages
    puts current_number_of_pages
    for i in (0..current_number_of_pages-1) do
      page = HTTParty.get(@url)
      current_number_of_pages = JSON.parse(page.body)["results"]["pageCount"]
      if i>current_number_of_pages
        return
      else
        puts "*****Scrapping page number #{i+1} of week starting #{@start_date}*****"
        @url_pages = "/page:#{i+1}"
        build_url
        getDataFromPage
      end
    end

  end

  def getDataFromPage
    
    page = HTTParty.get(@url)
    puts @url
    sleep(3)
    results_json = JSON.parse(page.body)
    search_results = results_json["results"]["hits"]

    search_results.each do |r|
      if (r["averagePrice"]!=nil && r["headline"]!=nil && r["detailPageUrl"]!=nil) 
        if (Classified.find_by_abritel_classified_id(r["listingId"]) == nil || Classified.find_by_abritel_classified_id(r["listingId"]).start_date != @start_date)
          geography = r["regionPathHierarchy"].split(":")
          
          if geography[4]!=nil
            quartier_geo = geography[4]
            else
            quartier_geo = nil
          end

          Classified.create(
            start_date:@start_date,
            end_date:@start_date+7,
            title:r["headline"],
            price:r["averagePrice"]["value"],
            link:r["detailPageUrl"],
            number_of_guests:r["sleeps"].to_i,
            abritel_id:r["listingNumber"].to_i,
            abritel_classified_id:r["listingId"],
            country:geography[0],
            region:geography[1],
            departement:geography[2],
            ville:geography[3],
            quartier:quartier_geo
            )
        else
          @double += 1
          puts "!!! already in database !!!"
        end
      end
    end
  end 

end